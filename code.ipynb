{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      "Processing Image with YOLO...\n",
      "\n",
      "0: 448x640 2 dogs, 292.9ms\n",
      "Speed: 2.3ms preprocess, 292.9ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Roboflow Prediction Response: {'predictions': [{'inference_id': '156ecbb8-c45f-4a6a-aa40-cdea54b1e9c9', 'time': 0.34250502299983054, 'image': {'width': 464, 'height': 538}, 'predictions': [{'class': 'Guard dog', 'class_id': 0, 'confidence': 0.9957}, {'class': 'Sheep', 'class_id': 6, 'confidence': 0.0011}, {'class': 'BH-Dorper', 'class_id': 1, 'confidence': 0.001}, {'class': 'WH-dorper', 'class_id': 5, 'confidence': 0.0008}, {'class': 'Red cow', 'class_id': 2, 'confidence': 0.0006}, {'class': 'Black cow', 'class_id': 3, 'confidence': 0.0005}, {'class': 'Coyote', 'class_id': 4, 'confidence': 0.0005}], 'top': 'Guard dog', 'confidence': 0.9957, 'image_path': 'Output/Detected_Animals\\\\object_20241206033004895164.jpg', 'prediction_type': 'ClassificationModel'}], 'image': (464, 538)}\n",
      "Roboflow Prediction Response: {'predictions': [{'inference_id': 'f32f0789-0b52-4199-a16d-21a832731c3e', 'time': 0.35311597200052347, 'image': {'width': 428, 'height': 588}, 'predictions': [{'class': 'Guard dog', 'class_id': 0, 'confidence': 0.9959}, {'class': 'BH-Dorper', 'class_id': 1, 'confidence': 0.0008}, {'class': 'WH-dorper', 'class_id': 5, 'confidence': 0.0008}, {'class': 'Sheep', 'class_id': 6, 'confidence': 0.0008}, {'class': 'Red cow', 'class_id': 2, 'confidence': 0.0006}, {'class': 'Black cow', 'class_id': 3, 'confidence': 0.0006}, {'class': 'Coyote', 'class_id': 4, 'confidence': 0.0006}], 'top': 'Guard dog', 'confidence': 0.9959, 'image_path': 'Output/Detected_Animals\\\\object_20241206033011251456.jpg', 'prediction_type': 'ClassificationModel'}], 'image': (428, 588)}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox, ttk\n",
    "from ultralytics import YOLO\n",
    "from datetime import datetime\n",
    "from roboflow import Roboflow\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageTk\n",
    "import threading\n",
    "\n",
    "# Initialize YOLOv11 and Roboflow models\n",
    "model = YOLO(\"yolo11m.pt\")  # Use YOLOv11 model\n",
    "rf = Roboflow(api_key=\"7P6wSkFD6Zb39ZYTL84S\")  # Private API Key \n",
    "project = rf.workspace(\"animal-class\").project(\"animal-class-cnxhg\")  #  Workspace and Project Name\n",
    "rf_model = project.version(5).model  # Use Version 5 of the Model diffrent version 1-5 excit but 5 recomended \n",
    "\n",
    "# Set up output directories\n",
    "output_dir_detected = \"Output/Detected_Animals\"\n",
    "output_dir_classified = \"Output/Classified_Animals\"\n",
    "output_dir_processed_video = \"Output/Processed_Videos\"\n",
    "\n",
    "os.makedirs(output_dir_detected, exist_ok=True) #no error if directories already exist.\n",
    "os.makedirs(output_dir_classified, exist_ok=True)#no error if directories already exist.\n",
    "os.makedirs(output_dir_processed_video, exist_ok=True)#no error if directories already exist.\n",
    "\n",
    "\n",
    "# Function to save cropped images for each detection\n",
    "def save_cropped_image(image_rgb, detection): #take the image \n",
    "    x1, y1, x2, y2, conf, cls_id = map(int, detection) # boxes coordinates\n",
    "    cropped_image = image_rgb[y1:y2, x1:x2] # crop the image only inside the box \n",
    "    cropped_filename = f'object_{datetime.now().strftime(\"%Y%m%d%H%M%S%f\")}.jpg'\n",
    "    cropped_path = os.path.join(output_dir_detected, cropped_filename)\n",
    "    cv2.imwrite(cropped_path, cv2.cvtColor(cropped_image, cv2.COLOR_RGB2BGR))\n",
    "    return cropped_path\n",
    "\n",
    "\n",
    "# GUI Setup\n",
    "class ObjectDetectionApp:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"Animal Detection and Classification \") # title\n",
    "        self.root.geometry(\"900x800\")# window size\n",
    "        self.root.configure(bg=\"#F5F5F5\")  #  gray background\n",
    "\n",
    "        # Header\n",
    "        header = tk.Label(\n",
    "            root,\n",
    "            text=\"Animal Detection and Classification\",\n",
    "            font=(\"Arial\", 20, \"bold\"),\n",
    "            bg=\"#2E3B4E\",\n",
    "            fg=\"white\",\n",
    "            pady=10\n",
    "        )\n",
    "        header.pack(fill=tk.X)\n",
    "\n",
    "        # Upload Section\n",
    "        upload_frame = tk.Frame(root, bg=\"#F5F5F5\")\n",
    "        upload_frame.pack(pady=20)\n",
    "        upload_button = ttk.Button(upload_frame, text=\"Upload Image or Video\", command=self.upload_file)\n",
    "        upload_button.pack()\n",
    "\n",
    "        # Threshold Sliders\n",
    "        threshold_frame = tk.Frame(root, bg=\"#F5F5F5\")\n",
    "        threshold_frame.pack(pady=20, fill=tk.X)\n",
    "\n",
    "        # Detection Threshold\n",
    "        detection_label = tk.Label(\n",
    "            threshold_frame, text=\"Detection Threshold:\", font=(\"Arial\", 12), bg=\"#F5F5F5\"\n",
    "        )\n",
    "        detection_label.grid(row=0, column=0, padx=10, sticky=\"w\")\n",
    "\n",
    "        self.detection_threshold = tk.DoubleVar(value=0.1)\n",
    "        detection_slider = ttk.Scale(\n",
    "            threshold_frame,\n",
    "            from_=0.1,\n",
    "            to=1.0,\n",
    "            orient=tk.HORIZONTAL,\n",
    "            variable=self.detection_threshold,\n",
    "            command=self.update_threshold_label,\n",
    "        )\n",
    "        detection_slider.grid(row=0, column=1, padx=10, sticky=\"we\")\n",
    "        self.detection_threshold_label = tk.Label(\n",
    "            threshold_frame,\n",
    "            text=f\"{self.detection_threshold.get():.2f}\",\n",
    "            font=(\"Arial\", 12),\n",
    "            bg=\"#F5F5F5\"\n",
    "        )\n",
    "        self.detection_threshold_label.grid(row=0, column=2, padx=10)\n",
    "\n",
    "        # Classification Threshold\n",
    "        classification_label = tk.Label(\n",
    "            threshold_frame, text=\"Classification Threshold:\", font=(\"Arial\", 12), bg=\"#F5F5F5\"\n",
    "        )\n",
    "        classification_label.grid(row=1, column=0, padx=10, sticky=\"w\")\n",
    "\n",
    "        self.classification_threshold = tk.DoubleVar(value=0.5)\n",
    "        classification_slider = ttk.Scale(\n",
    "            threshold_frame,\n",
    "            from_=0.1,\n",
    "            to=1.0,\n",
    "            orient=tk.HORIZONTAL,\n",
    "            variable=self.classification_threshold,\n",
    "            command=self.update_threshold_label,\n",
    "        )\n",
    "        classification_slider.grid(row=1, column=1, padx=10, sticky=\"we\")\n",
    "        self.classification_threshold_label = tk.Label(\n",
    "            threshold_frame,\n",
    "            text=f\"{self.classification_threshold.get():.2f}\",\n",
    "            font=(\"Arial\", 12),\n",
    "            bg=\"#F5F5F5\"\n",
    "        )\n",
    "        self.classification_threshold_label.grid(row=1, column=2, padx=10)\n",
    "\n",
    "        threshold_frame.columnconfigure(1, weight=1)\n",
    "\n",
    "        # Progress Bar\n",
    "        self.progress_bar = ttk.Progressbar(self.root, orient=\"horizontal\", length=900, mode=\"determinate\")\n",
    "        self.progress_bar.pack(pady=20)\n",
    "\n",
    "        # Canvas for Image Display\n",
    "        self.canvas_frame = tk.Frame(self.root, bg=\"#D3D3D3\", relief=tk.GROOVE, bd=2)\n",
    "        self.canvas_frame.pack(fill=tk.BOTH, expand=True, padx=20, pady=10)\n",
    "\n",
    "        self.canvas = tk.Canvas(self.canvas_frame, bg=\"#FFFFFF\")\n",
    "        self.canvas.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "        # To store the last uploaded image path\n",
    "        self.last_image_path = None\n",
    "\n",
    "    def upload_file(self): # let the user browse an image or video to upload must be jpg/png/mp4 file only \n",
    "        file_path = filedialog.askopenfilename(filetypes=[(\"Image/Video files\", \"*.jpg *.png *.mp4\")])\n",
    "        if file_path:\n",
    "            if file_path.endswith(('.jpg', '.png')):\n",
    "                self.last_image_path = file_path\n",
    "                self.process_image(file_path)\n",
    "            elif file_path.endswith('.mp4'):\n",
    "                threading.Thread(target=self.process_video, args=(file_path,)).start()\n",
    "            else:\n",
    "                messagebox.showerror(\"Invalid File\", \"Please upload a .jpg, .png, or .mp4 file.\")\n",
    "\n",
    "    def process_image(self, image_path): # pass the image to yolo then crop the detection and sent it to roboflow and display results on gui \n",
    "        image = cv2.imread(image_path)\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        print(\"Processing Image with YOLO...\")\n",
    "        results = model(image_rgb)\n",
    "        processed_img_path = self.detect_and_classify(image_rgb, results)\n",
    "        self.display_image(processed_img_path)\n",
    "\n",
    "    def process_video(self, video_path): # same as images \n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        frame_rate = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "        frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        processed_frames = 0\n",
    "\n",
    "        # Define the output video path\n",
    "        output_video_path = os.path.join(output_dir_processed_video, f\"processed_{datetime.now().strftime('%Y%m%d%H%M%S')}.mp4\")\n",
    "        out = cv2.VideoWriter(\n",
    "            output_video_path, cv2.VideoWriter_fourcc(*'mp4v'), frame_rate, (frame_width, frame_height)\n",
    "        )\n",
    "\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            results = model(frame_rgb)\n",
    "\n",
    "            if results and hasattr(results[0], 'boxes') and results[0].boxes.data.numel() > 0:\n",
    "                detections = results[0].boxes.data\n",
    "                for det in detections:\n",
    "                    x1, y1, x2, y2, conf, cls_id = det[:6].tolist()\n",
    "                    conf = float(conf)\n",
    "\n",
    "                    if conf >= self.detection_threshold.get():\n",
    "                        x1, y1, x2, y2 = map(int, [x1, y1, x2, y2])\n",
    "                        cropped_image = frame_rgb[y1:y2, x1:x2]\n",
    "\n",
    "                        # Save cropped image temporarily\n",
    "                        cropped_filename = f'temp_cropped_{datetime.now().strftime(\"%Y%m%d%H%M%S%f\")}.jpg'\n",
    "                        cropped_path = os.path.join(output_dir_detected, cropped_filename)\n",
    "                        cv2.imwrite(cropped_path, cv2.cvtColor(cropped_image, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "                        try:\n",
    "                            prediction = rf_model.predict(cropped_path).json()\n",
    "                            print(f\"Roboflow Prediction Response: {prediction}\")\n",
    "\n",
    "                            if \"predictions\" in prediction and len(prediction[\"predictions\"]) > 0:\n",
    "                                top_prediction = prediction[\"predictions\"][0]\n",
    "                                obj_class = top_prediction.get(\"class\", top_prediction.get(\"top\", \"unknown\"))\n",
    "                                confidence = top_prediction.get(\"confidence\", 0)\n",
    "\n",
    "                                if confidence >= self.classification_threshold.get():\n",
    "                                    label = f\"{obj_class} ({confidence * 100:.2f}%)\"\n",
    "                                    color = (0, 0, 255) if obj_class.lower() == \"coyote\" else (0, 255, 0)\n",
    "                                    cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "                                    cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "                        except Exception as e:\n",
    "                            print(f\"Error classifying cropped image: {e}\")\n",
    "\n",
    "            out.write(frame)\n",
    "            processed_frames += 1\n",
    "            self.progress_bar[\"value\"] = (processed_frames / frame_count) * 100\n",
    "            self.root.update()\n",
    "\n",
    "        cap.release()\n",
    "        out.release()\n",
    "        self.progress_bar[\"value\"] = 0\n",
    "        messagebox.showinfo(\"Processing Complete\", f\"Processed video saved to {output_video_path}\")\n",
    "\n",
    "    def detect_and_classify(self, image_rgb, results):\n",
    "        detection_threshold = self.detection_threshold.get()\n",
    "        classification_threshold = self.classification_threshold.get()\n",
    "\n",
    "        plt.figure(figsize=(12, 8), dpi=150)\n",
    "        plt.imshow(image_rgb)\n",
    "        ax = plt.gca()\n",
    "\n",
    "        if results and hasattr(results[0], 'boxes') and results[0].boxes.data.numel() > 0:\n",
    "            detections = results[0].boxes.data\n",
    "            for det in detections:\n",
    "                x1, y1, x2, y2, conf, cls_id = det[:6].tolist()\n",
    "                if conf >= detection_threshold:\n",
    "                    try:\n",
    "                        cropped_path = save_cropped_image(image_rgb, [x1, y1, x2, y2, conf, cls_id])\n",
    "                        prediction = rf_model.predict(cropped_path).json()\n",
    "                        print(f\"Roboflow Prediction Response: {prediction}\")\n",
    "\n",
    "                        if \"predictions\" in prediction and len(prediction[\"predictions\"]) > 0:\n",
    "                            top_prediction = prediction[\"predictions\"][0]\n",
    "                            obj_class = top_prediction.get(\"class\", top_prediction.get(\"top\", \"unknown\"))\n",
    "                            confidence = top_prediction.get(\"confidence\", 0)\n",
    "\n",
    "                            if confidence >= classification_threshold:\n",
    "                                color = \"red\" if obj_class.lower() == \"coyote\" else \"green\"\n",
    "                                rect = plt.Rectangle(\n",
    "                                    (x1, y1), x2 - x1, y2 - y1,\n",
    "                                    linewidth=2, edgecolor=color, facecolor=\"none\"\n",
    "                                )\n",
    "                                ax.add_patch(rect)\n",
    "                                ax.text(\n",
    "                                    x1, y1, f\"{obj_class}: {confidence * 100:.2f}%\",\n",
    "                                    color=\"Black\", fontsize=14, backgroundcolor=color\n",
    "                                )\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error during classification: {e}\")\n",
    "\n",
    "        plt.axis(\"off\")\n",
    "        output_path = os.path.join(output_dir_classified, f\"{datetime.now().strftime('%Y%m%d%H%M%S')}.jpg\")\n",
    "        plt.savefig(output_path, bbox_inches=\"tight\", dpi=150)\n",
    "        plt.close()\n",
    "        return output_path\n",
    "\n",
    "    def display_image(self, path):\n",
    "        img = Image.open(path)\n",
    "        img = img.resize((900, 500), Image.LANCZOS)\n",
    "        img_tk = ImageTk.PhotoImage(img)\n",
    "        self.canvas.create_image(0, 0, anchor=tk.NW, image=img_tk)\n",
    "        self.canvas.image = img_tk\n",
    "\n",
    "    def update_threshold_label(self, event=None):\n",
    "        self.detection_threshold_label.config(text=f\"{self.detection_threshold.get():.2f}\")\n",
    "        self.classification_threshold_label.config(text=f\"{self.classification_threshold.get():.2f}\")\n",
    "\n",
    "\n",
    "# Run the app\n",
    "if __name__ == \"__main__\":\n",
    "    root = tk.Tk()\n",
    "    app = ObjectDetectionApp(root)\n",
    "    root.mainloop()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
